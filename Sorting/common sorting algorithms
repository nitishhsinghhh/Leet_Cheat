
There are many sorting algorithms, each with their own strengths and weaknesses. Some of the most common sorting algorithms include:

 1. Bubble sort: repeatedly steps through the list to be sorted, compares each pair of adjacent items and swaps them if they are in the wrong order.
 2. Selection sort: repeatedly selects the next smallest (or largest) element from the unsorted portion of the list and moves it to its proper position in the sorted       portion of the list.
 3. Insertion sort: builds the final sorted list one item at a time by repeatedly removing one element from the input data, finding the location it belongs within the     sorted list, and inserting it there.
 4. Heap sort: builds a binary heap from the list, then repeatedly extracts the maximum element from the heap and places it at the end of the sorted list.
 5. Counting sort: A sorting technique based on keys between a specific range. It works by counting the number of objects having distinct key values (kind of hashing).     Then do some arithmetic to calculate the position of each object in the output sequence.
 6. Merge sort: divides the list in half, recursively sorts each half, and then merges the two sorted halves back together.
 7. Quick sort: selects a "pivot" element from the list and partition the other elements into two sub-lists, according to whether they are less than or greater than       the pivot. The sub-lists are then recursively sorted.

The choice of sorting algorithm depends on the specific requirements of the application, such as the size of the list to be sorted and the amount of memory available.

============================================================================================
1. Bubble Sort:
   Time Complexity : Best => O(n) , Worst & Average => O(n*n)
   Space Complexity: O(1) 
   Stability: Stable
   Is-In-Place: In-Place	
   When to use: 1. If array is of small size 
		2. If array is of large size but nearly sorted
   Remarks: Easiest to implement	
============================================================================================
2. Selection Sort:
   Time Complexity : Best & Worst & Average => O(n*n)
   Space Complexity: O(1) 
   Stability: Not-Stable
   Is-In-Place: In-Place
   When to use: 1. If array is of small size
		2. To minimise the number of swaps
   Remarks: Bubble sort has more number of swaps as compare to selection Sort but bubble sort has better best time complexity. It can also be implemented as stabaly. Selection sort makes O(n) swaps which is minimum among all sorting algorithms mentioned above.	
============================================================================================
3. Insertion Sort:
   Time Complexity : Best => O(n) , Worst & Average => O(n*n)
   Space Complexity: O(1) 
   Stability: Stable
   Is-In-Place: In-Place
   When to use: 1. If array is of small size and nearly sorted
   Remarks: Standard Libraray of C uses this algo when n becomes smaller than a threshold and for small size it is better than merge and quick sort becasue of low constant values and non
   recusive in nature.
============================================================================================
4. Heap Sort:
   Time Complexity : Best & Worst & Average => O(nLog(n))
   Space Complexity: O(1) 
   Stability: Not-Stable
   Is-In-Place: In-Place
   When to use: When the input array is large and stable sort is not required.		
   Remarks: It always guaranteed to be O(nLog(n)) with constant space which solves the problem of overflow of address space of a process which may occur in merge and quick sort(recursive stack).
============================================================================================
5. Counting Sort:
   Time Complexity : Best & Worst & Average => O(n+k)
   Space Complexity: O(n+k) 
   Stability: Not-Stable
   Is-In-Place: In-Place
============================================================================================
6. Merge Sort:
   Time Complexity : Best & Worst & Average => O(nLog(n))
   Space Complexity: O(n) 
   Stability: Stable 
   Is-In-Place: Not-In-Place
   Tag: Divide & Conquer
   When to use: 1. When we don't have random access(linked list) [R.A like as we have in array]
                2. When array is not to large.
============================================================================================
7. Quick Sort:
   Time Complexity : Best => O(nLog(n)), Worst => O(n*n) 
   Space Complexity: O(n) 
   Stability: Not-Stable 
   Is-In-Place: In-Place
   Tag: Divide & Conquer
   When to use: 1. It is prefered over merge sort for extremely large array
                 2. When you don't care about worst case complexity
============================================================================================
             Quick Sort                    *    Merge Sort 
1.Time       O(nLog(n)),O(n*n).            *    O(nLog(n))
2.Space      O(1).                         *    O(n)
3.Advantage  When random access is there.  *    When random access is costly(i.e Linked List)
4.Stability  Not Stable.                   *    Stable
5.In-Place   In-Place.                     *    Not-In-Place
6.Address    Never Rise.                   *    May arise when array/list is extremely large
============================================================================================
